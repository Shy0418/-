{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "# File: so-pmi.py\n",
    "# Author: lhy<lhy_in_blcu@126.com,https://huangyong.github.io>\n",
    "# Date: 18-4-4\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "import jieba\n",
    "import math,time\n",
    "import datetime\n",
    "\n",
    "class ChineseSoPmi:\n",
    "    def __init__(self, inputtext_file, seedword_txtfile, pos_candi_txt_file, neg_candi_txtfile):\n",
    "\n",
    "        self.text_file = inputtext_file\n",
    "        self.pos_candi_txt_file = pos_candi_txt_file\n",
    "        self.neg_candi_txtfile = neg_candi_txtfile\n",
    "        self.seedword_txtfile = seedword_txtfile\n",
    "\n",
    "    '''分词'''\n",
    "    def seg_corpus(self, train_data, seedword_txtfile):\n",
    "        #将情感词加入到用户词典当中，保证分词能够将种子情感词切开\n",
    "        sentiment_words = [line.strip().split('\\t')[0] for line in open(seedword_txtfile, encoding='utf-8')]\n",
    "        for word in sentiment_words:\n",
    "            jieba.add_word(word)\n",
    "        seg_data = list()\n",
    "        count = 0\n",
    "        for line in open(train_data, encoding='utf-8'):\n",
    "            line = line.strip()\n",
    "            count += 1\n",
    "            if line:\n",
    "                seg_data.append([word.word for word in pseg.cut(line) if word.flag[0] not in ['u','w','x','p','q','m']])\n",
    "            else:\n",
    "                continue\n",
    "        return seg_data\n",
    "\n",
    "    '''统计搭配次数'''\n",
    "    def collect_cowords(self, seedword_txtfile, seg_data):\n",
    "        def check_words(sent):\n",
    "            if set(sentiment_words).intersection(set(sent)):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        cowords_list = list()\n",
    "        window_size = 5\n",
    "        count = 0\n",
    "        sentiment_words = [line.strip().split('\\t')[0] for line in open(seedword_txtfile, encoding='utf-8')]\n",
    "        for sent in seg_data:\n",
    "            count += 1\n",
    "            if check_words(sent):\n",
    "                for index, word in enumerate(sent):\n",
    "                    if index < window_size:\n",
    "                        left = sent[:index]\n",
    "                    else:\n",
    "                        left = sent[index - window_size: index]\n",
    "                    if index + window_size > len(sent):\n",
    "                        right = sent[index + 1:]\n",
    "                    else:\n",
    "                        right = sent[index: index + window_size + 1]\n",
    "                    context = left + right + [word]\n",
    "                    if check_words(context):\n",
    "                        for index_pre in range(0, len(context)):\n",
    "                            if check_words([context[index_pre]]):\n",
    "                                for index_post in range(index_pre + 1, len(context)):\n",
    "                                    cowords_list.append(context[index_pre] + '@' + context[index_post])\n",
    "        return cowords_list\n",
    "\n",
    "    '''计算So-Pmi值'''\n",
    "    def collect_candiwords(self, seg_data, cowords_list, seedword_txtfile):\n",
    "        '''互信息计算公式'''\n",
    "        def compute_mi(p1, p2, p12):\n",
    "            return math.log2(p12) - math.log2(p1) - math.log2(p2)\n",
    "        '''统计词频'''\n",
    "        def collect_worddict(seg_data):\n",
    "            word_dict = dict()\n",
    "            all = 0\n",
    "            for line in seg_data:\n",
    "                for word in line:\n",
    "                    if word not in word_dict:\n",
    "                        word_dict[word] = 1\n",
    "                    else:\n",
    "                        word_dict[word] += 1\n",
    "            all = sum(word_dict.values())\n",
    "            return word_dict, all\n",
    "        '''统计词共现次数'''\n",
    "        def collect_cowordsdict(cowords_list):\n",
    "            co_dict = dict()\n",
    "            candi_words = list()\n",
    "            for co_words in cowords_list:\n",
    "                candi_words.extend(co_words.split('@'))\n",
    "                if co_words not in co_dict:\n",
    "                    co_dict[co_words] = 1\n",
    "                else:\n",
    "                    co_dict[co_words] += 1\n",
    "            return co_dict, candi_words\n",
    "        '''收集种子情感词'''\n",
    "        def collect_sentiwords(seedword_txtfile, word_dict):\n",
    "            pos_words = set([line.strip().split('\\t')[0] for line in open(seedword_txtfile, encoding='utf-8') if\n",
    "                             line.strip().split('\\t')[1] == 'pos']).intersection(set(word_dict.keys()))\n",
    "            neg_words = set([line.strip().split('\\t')[0] for line in open(seedword_txtfile, encoding='utf-8') if\n",
    "                             line.strip().split('\\t')[1] == 'neg']).intersection(set(word_dict.keys()))\n",
    "            return pos_words, neg_words\n",
    "        '''计算sopmi值'''\n",
    "        def compute_sopmi(candi_words, pos_words, neg_words, word_dict, co_dict, all):\n",
    "            pmi_dict = dict()\n",
    "            for candi_word in set(candi_words):\n",
    "                pos_sum = 0.0\n",
    "                neg_sum = 0.0\n",
    "                for pos_word in pos_words:\n",
    "                    p1 = word_dict[pos_word] / all\n",
    "                    p2 = word_dict[candi_word] / all\n",
    "                    pair = pos_word + '@' + candi_word\n",
    "                    if pair not in co_dict:\n",
    "                        continue\n",
    "                    p12 = co_dict[pair] / all\n",
    "                    pos_sum += compute_mi(p1, p2, p12)\n",
    "\n",
    "                for neg_word in neg_words:\n",
    "                    p1 = word_dict[neg_word] / all\n",
    "                    p2 = word_dict[candi_word] / all\n",
    "                    pair = neg_word + '@' + candi_word\n",
    "                    if pair not in co_dict:\n",
    "                        continue\n",
    "                    p12 = co_dict[pair] / all\n",
    "                    neg_sum += compute_mi(p1, p2, p12)\n",
    "\n",
    "                so_pmi = pos_sum - neg_sum\n",
    "                pmi_dict[candi_word] = so_pmi\n",
    "            return pmi_dict\n",
    "\n",
    "        word_dict, all = collect_worddict(seg_data)\n",
    "        co_dict, candi_words = collect_cowordsdict(cowords_list)\n",
    "        pos_words, neg_words = collect_sentiwords(seedword_txtfile, word_dict)\n",
    "        pmi_dict = compute_sopmi(candi_words, pos_words, neg_words, word_dict, co_dict, all)\n",
    "        return pmi_dict\n",
    "\n",
    "    '''保存结果'''\n",
    "    def save_candiwords(self, pmi_dict, pos_candi_txt_file, neg_candi_txtfile):\n",
    "        def get_tag(word):\n",
    "            if word:\n",
    "                return [item.flag for item in pseg.cut(word)][0]\n",
    "            else:\n",
    "                return 'x'\n",
    "        pos_dict = dict()\n",
    "        neg_dict = dict()\n",
    "        f_neg = open(neg_candi_txtfile, 'w+', encoding='utf-8')\n",
    "        f_pos = open(pos_candi_txt_file, 'w+', encoding='utf-8')\n",
    "\n",
    "        for word, word_score in pmi_dict.items():\n",
    "            if word_score > 0:\n",
    "                pos_dict[word] = word_score\n",
    "            else:\n",
    "                neg_dict[word] = abs(word_score)\n",
    "\n",
    "        for word, pmi in sorted(pos_dict.items(), key=lambda asd:asd[1], reverse=True):\n",
    "            f_pos.write(word + ',' + str(pmi) + ',' + 'pos'+ '\\n')\n",
    "        for word, pmi in sorted(neg_dict.items(), key=lambda asd:asd[1], reverse=True):\n",
    "            f_neg.write(word + ',' + str(pmi) + ',' + 'neg' + '\\n')\n",
    "        f_neg.close()\n",
    "        f_pos.close()\n",
    "        return\n",
    "\n",
    "    def sopmi(self):\n",
    "        print('step 1/4:...seg corpus ...')\n",
    "        start_time  = time.time()\n",
    "        start_time  = datetime.datetime.now()\n",
    "        seg_data = self.seg_corpus(self.text_file, self.seedword_txtfile)\n",
    "        # end_time1 = time.time()\n",
    "        end_time1 = datetime.datetime.now()\n",
    "        print('step 1/4 finished:...cost {0}...'.format((end_time1 - start_time)))\n",
    "        print('step 2/4:...collect cowords ...')\n",
    "        cowords_list = self.collect_cowords(self.seedword_txtfile, seg_data)\n",
    "        # end_time2 = time.time()\n",
    "        end_time2 = datetime.datetime.now()\n",
    "        print('step 2/4 finished:...cost {0}...'.format((end_time2 - end_time1)))\n",
    "        print('step 3/4:...compute sopmi ...')\n",
    "        pmi_dict = self.collect_candiwords(seg_data, cowords_list, self.seedword_txtfile)\n",
    "        # end_time3 = time.time()\n",
    "        end_time3 = datetime.datetime.now()\n",
    "        print('step 1/4 finished:...cost {0}...'.format((end_time3 - end_time2)))\n",
    "        print('step 4/4:...save candiwords ...')\n",
    "        self.save_candiwords(pmi_dict, self.pos_candi_txt_file, self.neg_candi_txtfile)\n",
    "        end_time = datetime.datetime.now()\n",
    "        print('finished! cost {0}'.format(end_time - start_time))\n",
    "\n",
    "def test():\n",
    "    sopmier = ChineseSoPmi(inputtext_file='corpus.txt',\n",
    "                           seedword_txtfile='seed_words.txt',\n",
    "                           pos_candi_txt_file='neg_candi.txt',\n",
    "                           neg_candi_txtfile='pos_candi.txt')\n",
    "    sopmier.sopmi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Existence.txt',encoding='utf-8',header=None)\n",
    "data\n",
    "data = data[0].to_list()\n",
    "data\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Esistence_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data:\n",
    "        f.write(i+'\\t'+'pos'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data1 = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Growth.txt',encoding='utf-8',header=None)\n",
    "data1 = data1[0].to_list()\n",
    "data1\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Esistence_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data1:\n",
    "        f.write(i+'\\t'+'neg'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data2 = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Relatedness.txt',encoding='utf-8',header=None)\n",
    "data2 = data2[0].to_list()\n",
    "data2\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Esistence_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data2:\n",
    "        f.write(i+'\\t'+'neg'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Shy0418\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/4:...seg corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.592 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start  =datetime.datetime.now()\n",
    "sopmier = ChineseSoPmi(inputtext_file=r'E:\\pythonProject\\需求分析词典\\知乎问题数据集.txt',\n",
    "                       seedword_txtfile=r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Esistence_seed_words.txt',\n",
    "                       pos_candi_txt_file=r'Existence_pos_candi.txt',\n",
    "                       neg_candi_txtfile=r'Existence_neg_candi.txt')\n",
    "sopmier.sopmi()\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Growth.txt',encoding='utf-8',header=None)\n",
    "data\n",
    "data = data[0].to_list()\n",
    "data\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data:\n",
    "        f.write(i+'\\t'+'pos'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data1 = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Existence.txt',encoding='utf-8',header=None)\n",
    "data1 = data1[0].to_list()\n",
    "data1\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data1:\n",
    "        f.write(i+'\\t'+'neg'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data1 = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Relatedness.txt',encoding='utf-8',header=None)\n",
    "data1 = data1[0].to_list()\n",
    "data1\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data1:\n",
    "        f.write(i+'\\t'+'neg'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sopmier = ChineseSoPmi(inputtext_file=r'E:\\pythonProject\\需求分析词典\\知乎问题数据集.txt',\n",
    "                       seedword_txtfile=r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_seed_words.txt',\n",
    "                       pos_candi_txt_file=r'Growth_pos_candi.txt',\n",
    "                       neg_candi_txtfile=r'Growth_neg_candi.txt')\n",
    "sopmier.sopmi()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Relatedness.txt',encoding='utf-8',header=None)\n",
    "data\n",
    "data = data[0].to_list()\n",
    "data\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data:\n",
    "        f.write(i+'\\t'+'pos'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data1 = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Existence.txt',encoding='utf-8',header=None)\n",
    "data1 = data1[0].to_list()\n",
    "data1\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data1:\n",
    "        f.write(i+'\\t'+'neg'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data1 = pd.read_table(r'E:\\pythonProject\\需求分析词典\\种子词选择\\同义词扩展后的Growth.txt',encoding='utf-8',header=None)\n",
    "data1 = data1[0].to_list()\n",
    "data1\n",
    "with open(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_seed_words.txt',encoding='utf-8',mode='a+') as f:\n",
    "    for i in data1:\n",
    "        f.write(i+'\\t'+'neg'+'\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sopmier = ChineseSoPmi(inputtext_file=r'E:\\pythonProject\\需求分析词典\\知乎问题数据集.txt',\n",
    "                       seedword_txtfile=r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_seed_words.txt',\n",
    "                       pos_candi_txt_file=r'Relatedness_pos_candi.txt',\n",
    "                       neg_candi_txtfile=r'Relatedness_neg_candi.txt')\n",
    "sopmier.sopmi()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "threshold1 = 0.45\n",
    "threshold2 = 0.45\n",
    "threshold3 = 0.45"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "       words         score\n0         病例  1.000000e+00\n1         确诊  8.632906e-01\n2          例  8.619289e-01\n3         首例  8.386238e-01\n4         患者  6.875511e-01\n...      ...           ...\n43266    刘庆香  2.978847e-06\n43267     说恨  1.644969e-06\n43268  memoQ  1.625884e-06\n43269     惠东  4.866190e-07\n43270    徐晓兰  0.000000e+00\n\n[43271 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>病例</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>确诊</td>\n      <td>8.632906e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>例</td>\n      <td>8.619289e-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>首例</td>\n      <td>8.386238e-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>患者</td>\n      <td>6.875511e-01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43266</th>\n      <td>刘庆香</td>\n      <td>2.978847e-06</td>\n    </tr>\n    <tr>\n      <th>43267</th>\n      <td>说恨</td>\n      <td>1.644969e-06</td>\n    </tr>\n    <tr>\n      <th>43268</th>\n      <td>memoQ</td>\n      <td>1.625884e-06</td>\n    </tr>\n    <tr>\n      <th>43269</th>\n      <td>惠东</td>\n      <td>4.866190e-07</td>\n    </tr>\n    <tr>\n      <th>43270</th>\n      <td>徐晓兰</td>\n      <td>0.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>43271 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Existence_pmi = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Existence_pos_candi.txt',encoding='utf-8',header=None,sep=',')\n",
    "# Existence\n",
    "Existence_pmi.columns=['words','score','sort']\n",
    "Existence_pmi = Existence_pmi[['words','score']]\n",
    "len(Existence_pmi)\n",
    "\n",
    "Existence_pmi.sort_values(by='score',ascending=False)\n",
    "Existence_pmi.drop_duplicates(subset=['words'],keep='first',inplace=True)\n",
    "min = Existence_pmi['score'].min()\n",
    "max = Existence_pmi['score'].max()\n",
    "\n",
    "for i in range(len(Existence_pmi)):\n",
    "    score = (Existence_pmi.iloc[i,1] - min) / (max - min)\n",
    "    Existence_pmi.iloc[i,1] = score\n",
    "\n",
    "pd.DataFrame(Existence_pmi).to_csv(r'Existence_candidata_score_ultimate_sopmi.txt',encoding='utf-8',sep = '\\t',header=0,index=0)\n",
    "Existence_pmi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "      words     score\n0        捷径  1.000000\n1        清北  0.948902\n2       参考书  0.891070\n3       考不上  0.820108\n4        直入  0.781623\n...     ...       ...\n21271    涨有  0.000015\n21272    厚码  0.000015\n21273    赞学  0.000005\n21274    系恐  0.000004\n21275  天下第一  0.000000\n\n[21276 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>捷径</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>清北</td>\n      <td>0.948902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>参考书</td>\n      <td>0.891070</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>考不上</td>\n      <td>0.820108</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>直入</td>\n      <td>0.781623</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21271</th>\n      <td>涨有</td>\n      <td>0.000015</td>\n    </tr>\n    <tr>\n      <th>21272</th>\n      <td>厚码</td>\n      <td>0.000015</td>\n    </tr>\n    <tr>\n      <th>21273</th>\n      <td>赞学</td>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>21274</th>\n      <td>系恐</td>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>21275</th>\n      <td>天下第一</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>21276 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Growth_pmi = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_pos_candi.txt',encoding='utf-8',header=None,sep=',')\n",
    "\n",
    "Growth_pmi.columns=['words','score','sort']\n",
    "Growth_pmi = Growth_pmi[['words','score']]\n",
    "len(Existence_pmi)\n",
    "# Growth_pmi = Growth_pmi.iloc[0:int(threshold*len(Growth_pmi)),0:2]\n",
    "\n",
    "Growth_pmi.sort_values(by='score',ascending=False)\n",
    "Growth_pmi.drop_duplicates(subset=['words'],keep='first',inplace=True)\n",
    "min = Growth_pmi['score'].min()\n",
    "max = Growth_pmi['score'].max()\n",
    "\n",
    "for i in range(len(Growth_pmi)):\n",
    "    score = (Growth_pmi.iloc[i,1] - min) / (max - min)\n",
    "    Growth_pmi.iloc[i,1] = score\n",
    "\n",
    "pd.DataFrame(Growth_pmi).to_csv(r'Growth_candidata_score_ultimate_sopmi.txt',encoding='utf-8',sep = '\\t',header=0,index=0)\n",
    "Growth_pmi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "      words     score\n0        背着  1.000000\n1        聊得  0.875182\n2        冷漠  0.808730\n3        删了  0.749389\n4       不懂事  0.727844\n...     ...       ...\n24960  孙庞斗智  0.000022\n24961  HREC  0.000021\n24962    换屏  0.000012\n24963    三生  0.000001\n24964    大仙  0.000000\n\n[24965 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>背着</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>聊得</td>\n      <td>0.875182</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>冷漠</td>\n      <td>0.808730</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>删了</td>\n      <td>0.749389</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>不懂事</td>\n      <td>0.727844</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24960</th>\n      <td>孙庞斗智</td>\n      <td>0.000022</td>\n    </tr>\n    <tr>\n      <th>24961</th>\n      <td>HREC</td>\n      <td>0.000021</td>\n    </tr>\n    <tr>\n      <th>24962</th>\n      <td>换屏</td>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>24963</th>\n      <td>三生</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>24964</th>\n      <td>大仙</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>24965 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Relatedness_pmi = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_pos_candi.txt',encoding='utf-8',header=None,sep=',')\n",
    "\n",
    "Relatedness_pmi.columns=['words','score','sort']\n",
    "Relatedness_pmi = Relatedness_pmi[['words','score']]\n",
    "len(Relatedness_pmi)\n",
    "# Relatedness_pmi = Relatedness_pmi.iloc[0:int(threshold*len(Relatedness_pmi)),0:2]\n",
    "Relatedness_pmi.sort_values(by='score',ascending=False)\n",
    "Relatedness_pmi.drop_duplicates(subset=['words'],keep='first',inplace=True)\n",
    "min = Relatedness_pmi['score'].min()\n",
    "max = Relatedness_pmi['score'].max()\n",
    "\n",
    "for i in range(len(Relatedness_pmi)):\n",
    "    score = (Relatedness_pmi.iloc[i,1] - min) / (max - min)\n",
    "    Relatedness_pmi.iloc[i,1] = score\n",
    "pd.DataFrame(Relatedness_pmi).to_csv(r'Relatedness_candidata_score_ultimate_sopmi.txt',encoding='utf-8',sep = '\\t',header=0,index=0)\n",
    "Relatedness_pmi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义集成学习的规则：\n",
    "### 如果so-pmi和w2v中都有，则取两个平均\n",
    "### 如果so-pmi中有，则取so-pmi\n",
    "### 如果w2v中有，则取w2v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# 求交集\n",
    "Existence_w2v = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\词向量法\\Existence_candidate_score_ultimate.txt',encoding='utf-8',header=None)\n",
    "Existence_w2v.columns=['words','score']\n",
    "# Existence_w2v\n",
    "Existence_pmi.columns=['words','score']\n",
    "Existence_pmi\n",
    "Existence_merge = pd.merge(Existence_w2v,Existence_pmi,on=['words'])\n",
    "Existence_merge\n",
    "# for i in range(len(Existence_merge)):\n",
    "#     Existence_merge.iloc[i,1] = (Existence_merge.iloc[i,1] + Existence_merge.iloc[i,2]) /2\n",
    "#     print(Existence.iloc[i,2])\n",
    "\n",
    "\n",
    "# Existence_merge.drop(columns='score_y')\n",
    "Existence_merge.drop(labels='score_y',inplace=True,axis=1)\n",
    "pd.DataFrame(Existence_merge).to_csv(r'Existence_merge.txt',encoding='utf-8',header=0,index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1\n0       柬埔寨  1.000000\n1       意大利  0.992389\n2        纽约  0.971933\n2        印度  0.971818\n4        泰国  0.971577\n...     ...       ...\n14767    地盘  0.026141\n14768  本质特征  0.026140\n14769   光复活  0.026138\n14771    山姆  0.026134\n14772    被贴  0.026129\n\n[22273 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>柬埔寨</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>意大利</td>\n      <td>0.992389</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>纽约</td>\n      <td>0.971933</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>印度</td>\n      <td>0.971818</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>泰国</td>\n      <td>0.971577</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14767</th>\n      <td>地盘</td>\n      <td>0.026141</td>\n    </tr>\n    <tr>\n      <th>14768</th>\n      <td>本质特征</td>\n      <td>0.026140</td>\n    </tr>\n    <tr>\n      <th>14769</th>\n      <td>光复活</td>\n      <td>0.026138</td>\n    </tr>\n    <tr>\n      <th>14771</th>\n      <td>山姆</td>\n      <td>0.026134</td>\n    </tr>\n    <tr>\n      <th>14772</th>\n      <td>被贴</td>\n      <td>0.026129</td>\n    </tr>\n  </tbody>\n</table>\n<p>22273 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 并-交，并去重，有重复的则留下第一个\n",
    "Existence_w2v = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\词向量法\\Existence_candidate_score_ultimate.txt',encoding='utf-8',header=None)\n",
    "Existence_pmi = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Existence_candidata_score_ultimate_sopmi.txt',encoding='utf-8',header=None)\n",
    "Existence_merge = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Existence_merge.txt',encoding='utf-8',header=None,sep=',')\n",
    "# Existence_merge\n",
    "# Existence_pmi\n",
    "# Existence_m2v\n",
    "Existence = pd.concat([Existence_merge,Existence_pmi,Existence_w2v],axis=0).drop_duplicates(subset=[0],keep='first')\n",
    "Existence.sort_values(by=1,ascending=False,inplace=True)\n",
    "Existence =Existence.iloc[0:int(len(Existence)*threshold1),0:2]\n",
    "\n",
    "pd.DataFrame(Existence).to_csv(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\Result\\Existence_words_score_ultimate.txt',encoding='utf-8',header=0,index=0)\n",
    "Existence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "    words   score_x\n0     礼智信  0.964601\n1      写作  0.930929\n2      韩语  0.925577\n3      完查  0.919864\n4     必修课  0.918332\n..    ...       ...\n966    必固  0.421614\n967    根因  0.420197\n968   ARE  0.420060\n969  赤壁之战  0.419904\n970  惯用手法  0.419866\n\n[971 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>score_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>礼智信</td>\n      <td>0.964601</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>写作</td>\n      <td>0.930929</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>韩语</td>\n      <td>0.925577</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>完查</td>\n      <td>0.919864</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>必修课</td>\n      <td>0.918332</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>966</th>\n      <td>必固</td>\n      <td>0.421614</td>\n    </tr>\n    <tr>\n      <th>967</th>\n      <td>根因</td>\n      <td>0.420197</td>\n    </tr>\n    <tr>\n      <th>968</th>\n      <td>ARE</td>\n      <td>0.420060</td>\n    </tr>\n    <tr>\n      <th>969</th>\n      <td>赤壁之战</td>\n      <td>0.419904</td>\n    </tr>\n    <tr>\n      <th>970</th>\n      <td>惯用手法</td>\n      <td>0.419866</td>\n    </tr>\n  </tbody>\n</table>\n<p>971 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求交集\n",
    "Growth_w2v = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\词向量法\\Growth_candidate_score_ultimate.txt',encoding='utf-8',header=None)\n",
    "Growth_w2v.columns=['words','score']\n",
    "# Existence_w2v\n",
    "Growth_pmi.columns=['words','score']\n",
    "Growth_pmi\n",
    "Growth_merge = pd.merge(Growth_w2v,Growth_pmi,on=['words'])\n",
    "# for i in range(len(Existence_merge)):\n",
    "#     Existence_merge.iloc[i,1] = (Existence_merge.iloc[i,1] + Existence_merge.iloc[i,2]) /2\n",
    "#     print(Existence.iloc[i,2])\n",
    "# Existence_merge.drop(columns='score_y')\n",
    "Growth_merge.drop(labels='score_y',inplace=True,axis=1)\n",
    "pd.DataFrame(Growth_merge).to_csv(r'Growth_merge.txt',encoding='utf-8',header=0,index=0,sep='\\t')\n",
    "Growth_merge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1\n0        二货猪  1.000000\n0         捷径  1.000000\n0        礼智信  0.964601\n1         清北  0.948902\n2         写出  0.942362\n...      ...       ...\n5213      作善  0.110428\n5215      生选  0.110413\n5218     生存力  0.110388\n5216      可数  0.110388\n5217  Nibiru  0.110388\n\n[12660 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>二货猪</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>捷径</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>礼智信</td>\n      <td>0.964601</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>清北</td>\n      <td>0.948902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>写出</td>\n      <td>0.942362</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5213</th>\n      <td>作善</td>\n      <td>0.110428</td>\n    </tr>\n    <tr>\n      <th>5215</th>\n      <td>生选</td>\n      <td>0.110413</td>\n    </tr>\n    <tr>\n      <th>5218</th>\n      <td>生存力</td>\n      <td>0.110388</td>\n    </tr>\n    <tr>\n      <th>5216</th>\n      <td>可数</td>\n      <td>0.110388</td>\n    </tr>\n    <tr>\n      <th>5217</th>\n      <td>Nibiru</td>\n      <td>0.110388</td>\n    </tr>\n  </tbody>\n</table>\n<p>12660 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Growth_w2v = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\词向量法\\Growth_candidate_score_ultimate.txt',encoding='utf-8',header=None,sep='\\t')\n",
    "Growth_pmi = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_candidata_score_ultimate_sopmi.txt',encoding='utf-8',header=None,sep='\\t')\n",
    "Growth_merge = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Growth_merge.txt',encoding='utf-8',header=None,sep='\\t')\n",
    "\n",
    "Growth_merge\n",
    "Growth = pd.concat([Growth_merge,Growth_pmi,Growth_w2v],axis=0).drop_duplicates(subset=[0],keep='first')\n",
    "Growth.sort_values(by=1,ascending=False,inplace=True)\n",
    "Growth = Growth.iloc[0:int(len(Growth)*threshold2),0:2]\n",
    "pd.DataFrame(Growth).to_csv(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\Result\\Growth_words_score_ultimate.txt',encoding='utf-8',header=0,index=0)\n",
    "Growth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "        words   score_x\n0          删掉  1.000000\n1         爱生气  0.990521\n2         男同学  0.958325\n3    radwimps  0.953351\n4         女同学  0.952418\n..        ...       ...\n901     Tiger  0.391899\n902       教师应  0.391119\n903        侠客  0.389109\n904       高圆圆  0.388872\n905        姿色  0.387997\n\n[906 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>score_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>删掉</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>爱生气</td>\n      <td>0.990521</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>男同学</td>\n      <td>0.958325</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>radwimps</td>\n      <td>0.953351</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>女同学</td>\n      <td>0.952418</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>901</th>\n      <td>Tiger</td>\n      <td>0.391899</td>\n    </tr>\n    <tr>\n      <th>902</th>\n      <td>教师应</td>\n      <td>0.391119</td>\n    </tr>\n    <tr>\n      <th>903</th>\n      <td>侠客</td>\n      <td>0.389109</td>\n    </tr>\n    <tr>\n      <th>904</th>\n      <td>高圆圆</td>\n      <td>0.388872</td>\n    </tr>\n    <tr>\n      <th>905</th>\n      <td>姿色</td>\n      <td>0.387997</td>\n    </tr>\n  </tbody>\n</table>\n<p>906 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#求交集\n",
    "Relatedness_w2v = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\词向量法\\Relatedness_candidate_score_ultimate.txt',encoding='utf-8',header=None)\n",
    "Relatedness_w2v.columns=['words','score']\n",
    "Relatedness_w2v\n",
    "Relatedness_pmi.columns=['words','score']\n",
    "Relatedness_pmi\n",
    "Relatedness_merge = pd.merge(Relatedness_w2v,Relatedness_pmi,on=['words'])\n",
    "Relatedness_merge.drop(labels='score_y',inplace=True,axis=1)\n",
    "pd.DataFrame(Relatedness_merge).to_csv(r'Relatedness_merge.txt',encoding='utf-8',header=0,index=0,sep='\\t')\n",
    "Relatedness_merge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1\n0           删掉  1.000000\n1          爱生气  0.990521\n2           男票  0.986755\n2          男同学  0.958325\n3     radwimps  0.953351\n...        ...       ...\n7364        酸臭  0.082415\n7365        睡出  0.082415\n7366        自含  0.082415\n7367      对簿公堂  0.082408\n7368      kiki  0.082396\n\n[13995 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>删掉</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>爱生气</td>\n      <td>0.990521</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>男票</td>\n      <td>0.986755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>男同学</td>\n      <td>0.958325</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>radwimps</td>\n      <td>0.953351</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7364</th>\n      <td>酸臭</td>\n      <td>0.082415</td>\n    </tr>\n    <tr>\n      <th>7365</th>\n      <td>睡出</td>\n      <td>0.082415</td>\n    </tr>\n    <tr>\n      <th>7366</th>\n      <td>自含</td>\n      <td>0.082415</td>\n    </tr>\n    <tr>\n      <th>7367</th>\n      <td>对簿公堂</td>\n      <td>0.082408</td>\n    </tr>\n    <tr>\n      <th>7368</th>\n      <td>kiki</td>\n      <td>0.082396</td>\n    </tr>\n  </tbody>\n</table>\n<p>13995 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Relatedness_w2v = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\词向量法\\Relatedness_candidate_score_ultimate.txt',encoding='utf-8',header=None,sep='\\t')\n",
    "Relatedness_pmi = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_candidata_score_ultimate_sopmi.txt',encoding='utf-8',header=None,sep='\\t')\n",
    "Relatedness_merge = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\test\\共现法\\Relatedness_merge.txt',encoding='utf-8',header=None,sep='\\t')\n",
    "\n",
    "Relatedness = pd.concat([Relatedness_merge,Relatedness_pmi,Relatedness_w2v],axis=0).drop_duplicates(subset=[0],keep='first')\n",
    "Relatedness.sort_values(by=1,ascending=False,inplace=True)\n",
    "Relatedness = Relatedness.iloc[0:int(len(Relatedness)*threshold3),0:2]\n",
    "pd.DataFrame(Relatedness).to_csv(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\Result\\Relatedness_words_score_ultimate.txt',encoding='utf-8',header=0,index=0)\n",
    "Relatedness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "\n",
    "def chinese(text):\n",
    "    \"\"\"\n",
    "    对中文数据进行处理，并将计算出的pmi保存到\"中文pmi计算.csv\"\n",
    "    \"\"\"\n",
    "    content = ''.join(re.findall(r'[\\u4e00-\\u9fa5]+', text))\n",
    "\n",
    "    words = jieba.cut(content)\n",
    "\n",
    "    words = [w for w in words if len(w)>1]\n",
    "\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "    finder = BigramCollocationFinder.from_words(words)\n",
    "\n",
    "    with open('中文pmi计算.csv','a+',encoding='utf-8',newline='') as csvf:\n",
    "\n",
    "        writer = csv.writer(csvf)\n",
    "\n",
    "        writer.writerow(('word1','word2','pmi_score'))\n",
    "\n",
    "        for row in finder.score_ngrams(bigram_measures.pmi):\n",
    "\n",
    "            data = (*row[0],row[1])\n",
    "            try:\n",
    "                writer.writerow(data)\n",
    "            except:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def english(text):\n",
    "    \"\"\"\n",
    "    对英文数据进行处理，并将计算出的pmi保存到\"english_pmi_computer.csv\"\n",
    "    \"\"\"\n",
    "\n",
    "    stopwordss = set(stopwords.words('english'))\n",
    "\n",
    "    stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "    words = tokenizer.tokenize(text)\n",
    "\n",
    "    words = [w for w in words if not w.isnumeric()]\n",
    "\n",
    "    words = [w.lower() for w in words]\n",
    "\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "\n",
    "    words = [w for w in words if w not in stopwordss]\n",
    "\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "    finder = BigramCollocationFinder.from_words(words)\n",
    "\n",
    "    with open('english_pmi_computer.csv','a+',encoding='gbk',newline='') as csvf:\n",
    "\n",
    "        writer = csv.writer(csvf)\n",
    "\n",
    "        writer.writerow(('word1','word2','pmi_score'))\n",
    "\n",
    "        for row in finder.score_ngrams(bigram_measures.pmi):\n",
    "\n",
    "            data = (*row[0],row[1])\n",
    "            try:\n",
    "                writer.writerow(data)\n",
    "            except:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pmi_score(file,lang,column='数据列'):\n",
    "    \"\"\"\n",
    "    计算pmi\n",
    "    :param file: 原始文本数据文件\n",
    "    :param lang: 数据的语言,参数为chinese或english\n",
    "    :param column: 如果文件为excel形式的文件，column为excel中的数据列\n",
    "\n",
    "    \"\"\"\n",
    "    #读取数据\n",
    "    text = ''\n",
    "    if 'csv' in file:\n",
    "        df = pd.read_csv(file)\n",
    "        rows = df.iterrows()\n",
    "        for row in rows:\n",
    "            text += row[1][column]\n",
    "    elif ('xlsx' in file) or ('xls' in file):\n",
    "        df = pd.read_excel(file)\n",
    "        rows = df.iterrows()\n",
    "        for row in rows:\n",
    "            text += row[1][column]\n",
    "    else:\n",
    "        text = open(file).read()\n",
    "\n",
    "    #对该语言的文本数据计算pmi\n",
    "    globals()[lang](text)\n",
    "\n",
    "#计算pmi\n",
    "pmi_score(file='test.txt',lang='chinese')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
