{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "Loss = []\n",
    "Acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zhihu = pd.read_table(r'知乎问题数据集.txt',encoding='utf-8',sep=',',header=None,error_bad_lines=False)\n",
    "# zhihu = pd.read_csv(r'E:\\论文\\数据\\知乎.csv',encoding='utf-8',sep=',',header=None,error_bad_lines=False)\n",
    "# zhihu.dropna(inplace=True)\n",
    "print('Existence：'+str(len(zhihu[zhihu[2]==0.0])))\n",
    "print('Growth:'+str(len(zhihu[zhihu[2]==1.0])))\n",
    "print('Relatedness:'+str(len(zhihu[zhihu[2]==2.0])))\n",
    "# zhihu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Existence_train_set = zhihu[zhihu[2]==0.0]\n",
    "Existence_train_set[1]\n",
    "Growth_train_set = zhihu[zhihu[2]==1.0]\n",
    "Growth_train_set\n",
    "Relatedness_train_set = zhihu[zhihu[2]==2.0]\n",
    "Relatedness_train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_set = pd.concat([Existence_train_set,Growth_train_set,Relatedness_train_set],axis=0)\n",
    "# train_set.iloc[329,]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "seed_words1 = pd.read_excel(r'E:\\论文\\数据\\WenXinV4.0师姐发的版本\\dic\\dictionary_all.xlsx',header=0,index_col=None)\n",
    "seed_words1\n",
    "seed_words = seed_words1['words'].to_list()\n",
    "seed_words\n",
    "jieba.load_userdict(r'E:\\pythonProject\\需求分析词典\\Seed_words.txt')\n",
    "def tokenize_zh(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return words\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_zh)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(len(Growth_train_set)):\n",
    "#     Growth_cut = tokenize_zh(Growth_train_set.iloc[i,1])\n",
    "#     print(Growth_cut)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(len(Relatedness_train_set)):\n",
    "#     Relatedness_cut = tokenize_zh(Relatedness_train_set.iloc[i,1])\n",
    "#     print(Relatedness_cut)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#遍历知乎数据集，给知乎数据集分词，以量化文本\n",
    "for i in range(len(zhihu)):\n",
    "    zhihu_cut = tokenize_zh(zhihu.iloc[i,0])\n",
    "    print(zhihu_cut)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def stopchineseword(segResult):\n",
    "    file = open(\"f:\\\\chineseStopWords.txt\",\"r\")\n",
    "    data = dict()\n",
    "    new_segResult=[]\n",
    "    for i in file.readlines(): #从文件中读取数据并将其添加到列表中\n",
    "        data.append(i.strip())\n",
    "    for i in segResult:\n",
    "        if i in data:  #比较是否为停用词\n",
    "            continue\n",
    "        else:\n",
    "            new_segResult.append(i)\n",
    "    return new_segResult"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Existence_dictionary = dict()\n",
    "Growth_dictionary = dict()\n",
    "Relatedness_dictionary = dict()\n",
    "Existence = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\Result\\Existence_words_score_ultimate.txt',encoding='utf-8',header=None,sep=',')\n",
    "Existence\n",
    "for i in range(len(Existence)):\n",
    "    # print(Existence.iloc[i,0])\n",
    "    Existence_dictionary[Existence.iloc[i,0]] = Existence.iloc[i,1]\n",
    "# print(Existence_dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import pprint\n",
    "Growth = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\Result\\Growth_words_score_ultimate.txt',encoding='utf-8',header=None,sep=',')\n",
    "# Growth\n",
    "for i in range(len(Growth)):\n",
    "    Growth_dictionary[Growth.iloc[i,0]] = Growth.iloc[i,1]\n",
    "# print(Growth_dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Relatedness = pd.read_table(r'E:\\pythonProject\\需求分析词典\\wordexpansion\\Result\\Relatedness_words_score_ultimate.txt',encoding='utf-8',header=None,sep = ',')\n",
    "for i in range(len(Relatedness)):\n",
    "    Relatedness_dictionary[Relatedness.iloc[i,0]] = Relatedness.iloc[i,1]\n",
    "# print(Relatedness_dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score=[]\n",
    "for i in range(len(Existence_train_set)):\n",
    "    Existence_cut = tokenize_zh(Existence_train_set.iloc[i,1])\n",
    "    # print(Existence_cut)\n",
    "    label = -1\n",
    "    Existence_score=0\n",
    "    Growth_score=0\n",
    "    Relatedness_score=0\n",
    "    for j1 in Existence_cut:\n",
    "        for k1 in Existence_dictionary.keys():\n",
    "            if(j1 == k1):\n",
    "                Existence_score += Existence_dictionary[j1]\n",
    "            else:\n",
    "                continue\n",
    "    for j2 in Existence_cut:\n",
    "        for k2 in Growth_dictionary.keys():\n",
    "            if(j2 == k2):\n",
    "                Growth_score += Growth_dictionary[k2]\n",
    "            else:\n",
    "                continue\n",
    "    for j3 in Existence_cut:\n",
    "         for k3 in Relatedness_dictionary.keys():\n",
    "             if(j3 == k3):\n",
    "                Relatedness_score += Relatedness_dictionary[k3]\n",
    "             else:\n",
    "                continue\n",
    "    # print(Existence_score)\n",
    "    # print(Growth_score)\n",
    "    # print(Relatedness_score)\n",
    "    if (Existence_score >= Growth_score) & (Existence_score >= Relatedness_score):\n",
    "        label = 0\n",
    "    elif (Growth_score >= Existence_score) & (Growth_score >= Relatedness_score):\n",
    "        label = 1\n",
    "    elif (Relatedness_score >= Existence_score) & (Relatedness_score >= Growth_score):\n",
    "        label = 2\n",
    "    # print('Label:'+str(label))\n",
    "    score.append(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(Growth_train_set)):\n",
    "    Growth_cut = tokenize_zh(Growth_train_set.iloc[i,1])\n",
    "    # print(Existence_cut)\n",
    "    label = -1\n",
    "    Existence_score=0\n",
    "    Growth_score=0\n",
    "    Relatedness_score=0\n",
    "    for j1 in Growth_cut:\n",
    "        for k1 in Existence_dictionary.keys():\n",
    "            if(j1 == k1):\n",
    "                Existence_score += Existence_dictionary[j1]\n",
    "            else:\n",
    "                continue\n",
    "    for j2 in Growth_cut:\n",
    "        for k2 in Growth_dictionary.keys():\n",
    "            if(j2 == k2):\n",
    "                Growth_score += Growth_dictionary[k2]\n",
    "            else:\n",
    "                continue\n",
    "    for j3 in Growth_cut:\n",
    "         for k3 in Relatedness_dictionary.keys():\n",
    "             if(j3 == k3):\n",
    "                Relatedness_score += Relatedness_dictionary[k3]\n",
    "             else:\n",
    "                continue\n",
    "    # print(Existence_score)\n",
    "    # print(Growth_score)\n",
    "    # print(Relatedness_score)\n",
    "    if (Existence_score > Growth_score) & (Existence_score > Relatedness_score):\n",
    "        label = 0\n",
    "    elif (Growth_score >= Existence_score) & (Growth_score >= Relatedness_score):\n",
    "        label = 1\n",
    "    elif (Relatedness_score > Existence_score) & (Relatedness_score > Growth_score):\n",
    "        label = 2\n",
    "    # print('Label:'+str(label))\n",
    "    score.append(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(Relatedness_train_set)):\n",
    "    Relatedness_cut = tokenize_zh(Relatedness_train_set.iloc[i,1])\n",
    "    # print(Relatedness_cut)\n",
    "    label = -1\n",
    "    Existence_score=0\n",
    "    Growth_score=0\n",
    "    Relatedness_score=0\n",
    "    for j1 in Relatedness_cut:\n",
    "        for k1 in Existence_dictionary.keys():\n",
    "            if(j1 == k1):\n",
    "                Existence_score += Existence_dictionary[j1]\n",
    "            else:\n",
    "                continue\n",
    "    for j2 in Relatedness_cut:\n",
    "        for k2 in Growth_dictionary.keys():\n",
    "            if(j2 == k2):\n",
    "                Growth_score += Growth_dictionary[k2]\n",
    "            else:\n",
    "                continue\n",
    "    for j3 in Relatedness_cut:\n",
    "         for k3 in Relatedness_dictionary.keys():\n",
    "             if(j3 == k3):\n",
    "                Relatedness_score += Relatedness_dictionary[k3]\n",
    "             else:\n",
    "                continue\n",
    "    # print(Existence_score)\n",
    "    # print(Growth_score)\n",
    "    # print(Relatedness_score)\n",
    "    if (Existence_score > Growth_score) & (Existence_score > Relatedness_score):\n",
    "        label = 0\n",
    "    elif (Growth_score > Existence_score) & (Growth_score > Relatedness_score):\n",
    "        label = 1\n",
    "    elif (Relatedness_score >= Existence_score) & (Relatedness_score >= Growth_score):\n",
    "        label = 2\n",
    "    # print('Label:'+str(label))\n",
    "    score.append(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,auc,log_loss,f1_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "import numpy as np\n",
    "y_pred = score\n",
    "y_true = train_set[2].tolist()\n",
    "\n",
    "y_pred = np.array(y_pred).reshape(-1,1)\n",
    "y_true = np.array(y_true).reshape(-1,1)\n",
    "one_hot = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_test = one_hot.fit_transform(y_pred)\n",
    "y_true = one_hot.fit_transform(y_true)\n",
    "# Loss.append(log_loss(y_true,y_pred))\n",
    "# Acc.append(accuracy_score(y_true,y_pred))\n",
    "print(accuracy_score(y_true,y_test))\n",
    "print(log_loss(y_true,y_test))\n",
    "# print(Loss)\n",
    "# print(Acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[14.46540559179871, 14.412994701973352, 14.412994701973352, 14.46540559179871, 14.46540559179871, 14.570227371449421, 14.412994701973352,6.761004787471136,5.188678092710409,3.7735840674257513,4.140460296203255]\n",
    "[0.5811836115326252, 0.582701062215478, 0.582701062215478, 0.5811836115326252, 0.5811836115326252, 0.5781487101669196, 0.582701062215478,0.765433245123123,0.8042488619119879,0.849772382397572, 0.8725341426403642,0.8907435508345979,0.8968133535660091, 0.8801213960546282,]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(score).to_csv(r'score.txt',encoding='utf-8',header=0,index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
